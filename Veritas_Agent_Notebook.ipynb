{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4d7e88",
   "metadata": {},
   "source": [
    "# Nemotron Veritas: AI Agent for Deconstructing Misinformation\n",
    "\n",
    "This notebook implements a sophisticated multi-agent system designed to act as a \"critical thinking amplifier\" using NVIDIA's Nemotron family of models. The system analyzes text to reveal rhetorical devices, logical fallacies, and persuasive techniques.\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "1. **Architect Agent** (nvidia-nemotron-nano-9b-v2)\n",
    "   - Analyzes text structure\n",
    "   - Extracts main thesis and supporting claims\n",
    "\n",
    "2. **Rhetoric Agent** (llama-3_3-nemotron-super-49b-v1_5)\n",
    "   - Examines claims for logical fallacies\n",
    "   - Uses RAG pipeline with fallacies knowledge base\n",
    "\n",
    "3. **Synthesizer Agent** (nvidia-nemotron-nano-9b-v2)\n",
    "   - Combines analyses\n",
    "   - Formats structured output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5864ad",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "First, we'll install and import all required dependencies. Run this cell to set up your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cb350a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q langchain langchain-community faiss-cpu openai python-dotenv tqdm sentence-transformers langchain-nvidia-ai-endpoints\n",
    "\n",
    "# Import dependencies\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings, NVIDIARerank\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3360b9d",
   "metadata": {},
   "source": [
    "## 2. API Configuration and Model Initialization\n",
    "\n",
    "Configure the NVIDIA API credentials and initialize our three Nemotron models. We'll create custom wrapper classes for each model to handle their specific requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "730f8b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gdwu0\\AppData\\Local\\Temp\\ipykernel_5128\\1596275397.py:12: DeprecationWarning: The 'max_tokens' parameter is deprecated and will be removed in a future version. Please use 'max_completion_tokens' instead.\n",
      "  ARCHITECT_MODEL = ChatNVIDIA(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gdwu0\\nemotron-veritas-local\\.venv\\Lib\\site-packages\\langchain_nvidia_ai_endpoints\\_common.py:229: UserWarning: Found nvidia/nvidia-nemotron-nano-9b-v2 in available_models, but type is unknown and inference may fail.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gdwu0\\AppData\\Local\\Temp\\ipykernel_5128\\1596275397.py:20: DeprecationWarning: The 'max_tokens' parameter is deprecated and will be removed in a future version. Please use 'max_completion_tokens' instead.\n",
      "  RHETORIC_MODEL = ChatNVIDIA(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Model Configuration\n",
    "NANO_API_KEY = \"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\"\n",
    "SUPER_API_KEY = \"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\"\n",
    "\n",
    "# Initialize our models using langchain-nvidia-ai-endpoints\n",
    "ARCHITECT_MODEL = ChatNVIDIA(\n",
    "    api_key=NANO_API_KEY,\n",
    "    model=\"nvidia/nvidia-nemotron-nano-9b-v2\",\n",
    "    temperature=0.3,\n",
    "    top_p=0.95,\n",
    "    max_tokens=2048\n",
    ")\n",
    "\n",
    "RHETORIC_MODEL = ChatNVIDIA(\n",
    "    api_key=SUPER_API_KEY,\n",
    "    model=\"nvidia/llama-3.3-nemotron-super-49b-v1.5\",\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    max_tokens=65536\n",
    ")\n",
    "\n",
    "EMBEDDING_MODEL = NVIDIAEmbeddings(\n",
    "    api_key=SUPER_API_KEY,\n",
    "    model=\"nvidia/llama-3.2-nv-embedqa-1b-v2\",\n",
    "    truncate=\"END\"  # Handle long texts gracefully\n",
    ")\n",
    "\n",
    "RERANKER_MODEL = NVIDIARerank(\n",
    "    api_key=SUPER_API_KEY,\n",
    "    model=\"nvidia/llama-3.2-nv-rerankqa-1b-v2\"\n",
    ")\n",
    "\n",
    "print(\"Models initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227cf72c",
   "metadata": {},
   "source": [
    "## 3. Knowledge Base Construction\n",
    "\n",
    "Now we'll create our knowledge base of logical fallacies and rhetorical devices. We'll use FAISS for vector storage and nvidia-embed-qa-4 for embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fb1fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created vector store with 2 fallacies\n"
     ]
    }
   ],
   "source": [
    "# Define our logical fallacies database\n",
    "LOGICAL_FALLACIES = [\n",
    "    {\n",
    "        \"name\": \"Ad Hominem\",\n",
    "        \"description\": \"Attacking the person instead of addressing their argument\",\n",
    "        \"example\": \"You can't trust his economic policy because he's never had a real job.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Straw Man\",\n",
    "        \"description\": \"Misrepresenting someone's argument to make it easier to attack\",\n",
    "        \"example\": \"Environmentalists want us to go back to living in caves without electricity.\"\n",
    "    },\n",
    "    # Add more fallacies here\n",
    "]\n",
    "\n",
    "# Create documents from fallacies\n",
    "documents = []\n",
    "for fallacy in LOGICAL_FALLACIES:\n",
    "    text = f\"Fallacy: {fallacy['name']}\\nDescription: {fallacy['description']}\\nExample: {fallacy['example']}\"\n",
    "    documents.append(Document(page_content=text, metadata=fallacy))\n",
    "\n",
    "# Create FAISS vector store with embeddings\n",
    "vectordb = FAISS.from_documents(documents, EMBEDDING_MODEL)\n",
    "\n",
    "# Create a retriever with reranking for better results\n",
    "base_retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "fallacy_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=base_retriever,\n",
    "    base_compressor=RERANKER_MODEL\n",
    ")\n",
    "\n",
    "print(f\"Created vector store with {len(LOGICAL_FALLACIES)} fallacies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7e28b",
   "metadata": {},
   "source": [
    "## 4. Architect Agent Implementation\n",
    "\n",
    "The Architect Agent analyzes the text structure to identify the main thesis and supporting claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "299a5a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architect Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class TextStructure:\n",
    "    thesis: str\n",
    "    claims: List[str]\n",
    "\n",
    "class ArchitectAgent:\n",
    "    def __init__(self, model: ChatNVIDIA):\n",
    "        self.model = model\n",
    "        self.prompt_template = \"\"\"\n",
    "        Analyze the following text and identify:\n",
    "        1. The main thesis (central argument)\n",
    "        2. The key supporting claims\n",
    "        \n",
    "        Text: {text}\n",
    "        \n",
    "        Output your analysis in JSON format with 'thesis' and 'claims' fields.\n",
    "        \"\"\"\n",
    "    \n",
    "    def analyze_structure(self, text: str) -> TextStructure:\n",
    "        prompt = self.prompt_template.format(text=text)\n",
    "        \n",
    "        # Get response from model using ChatNVIDIA interface\n",
    "        messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "        response = self.model.invoke(messages).content\n",
    "        \n",
    "        # Parse JSON response\n",
    "        try:\n",
    "            result = json.loads(response)\n",
    "            return TextStructure(\n",
    "                thesis=result['thesis'],\n",
    "                claims=result['claims']\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error parsing Architect agent response: {e}\")\n",
    "            raise\n",
    "\n",
    "# Initialize Architect agent\n",
    "architect = ArchitectAgent(ARCHITECT_MODEL)\n",
    "print(\"Architect Agent initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c0aa00",
   "metadata": {},
   "source": [
    "## 5. Rhetoric Agent Implementation\n",
    "\n",
    "The Rhetoric Agent examines each claim for logical fallacies using RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a610217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhetoric Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class FallacyAnalysis:\n",
    "    claim: str\n",
    "    detected_fallacies: List[Dict[str, Any]]\n",
    "    explanation: str\n",
    "\n",
    "class RhetoricAgent:\n",
    "    def __init__(self, model: ChatNVIDIA, retriever: ContextualCompressionRetriever):\n",
    "        self.model = model\n",
    "        self.retriever = retriever\n",
    "        self.prompt_template = \"\"\"You are a logical fallacy detection system. Your task is to analyze the following claim for logical fallacies using the provided context.\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Relevant fallacy patterns for reference:\n",
    "{context}\n",
    "\n",
    "Analyze the claim and output your findings in the following JSON format EXACTLY:\n",
    "{{\n",
    "    \"detected_fallacies\": [\n",
    "        {{\"name\": \"Fallacy Name\", \"type\": \"Type of Fallacy\"}}\n",
    "    ],\n",
    "    \"explanation\": \"Detailed explanation of how these fallacies are used in the claim\"\n",
    "}}\n",
    "\n",
    "Ensure your response is ONLY the JSON object, with no additional text before or after.\n",
    "If no fallacies are found, return an empty list for detected_fallacies.\n",
    "\"\"\"\n",
    "    \n",
    "    def analyze_claim(self, claim: str) -> FallacyAnalysis:\n",
    "        # Get relevant fallacy patterns with reranking\n",
    "        docs = self.retriever.invoke(claim)  # Using new invoke method\n",
    "        context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # Generate analysis\n",
    "        messages = [{\"role\": \"system\", \"content\": self.prompt_template.format(claim=claim, context=context)}]\n",
    "        response = self.model.invoke(messages).content.strip()\n",
    "        \n",
    "        try:\n",
    "            # Try to fix common JSON formatting issues\n",
    "            if not response.startswith('{'):\n",
    "                # Find the first occurrence of '{'\n",
    "                start_idx = response.find('{')\n",
    "                if start_idx != -1:\n",
    "                    response = response[start_idx:]\n",
    "                    # Find the last occurrence of '}'\n",
    "                    end_idx = response.rfind('}')\n",
    "                    if end_idx != -1:\n",
    "                        response = response[:end_idx + 1]\n",
    "            \n",
    "            result = json.loads(response)\n",
    "            \n",
    "            # Ensure the required fields exist\n",
    "            if \"detected_fallacies\" not in result or \"explanation\" not in result:\n",
    "                result = {\n",
    "                    \"detected_fallacies\": [],\n",
    "                    \"explanation\": \"Failed to detect fallacies in a structured way.\"\n",
    "                }\n",
    "                \n",
    "            return FallacyAnalysis(\n",
    "                claim=claim,\n",
    "                detected_fallacies=result['detected_fallacies'],\n",
    "                explanation=result['explanation']\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error parsing Rhetoric agent response: {e}\")\n",
    "            logging.error(f\"Raw response: {response}\")\n",
    "            # Return a safe fallback response\n",
    "            return FallacyAnalysis(\n",
    "                claim=claim,\n",
    "                detected_fallacies=[],\n",
    "                explanation=\"Failed to analyze this claim due to processing error.\"\n",
    "            )\n",
    "\n",
    "# Initialize Rhetoric agent\n",
    "rhetoric = RhetoricAgent(RHETORIC_MODEL, fallacy_retriever)\n",
    "print(\"Rhetoric Agent initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dfa908",
   "metadata": {},
   "source": [
    "## 6. Synthesizer Agent Implementation\n",
    "\n",
    "The Synthesizer Agent combines analyses into a structured report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d6cb9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizer Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class AnalysisReport:\n",
    "    text: str\n",
    "    thesis: str\n",
    "    claims_analysis: List[FallacyAnalysis]\n",
    "    summary: str\n",
    "\n",
    "class SynthesizerAgent:\n",
    "    def __init__(self, model: ChatNVIDIA):\n",
    "        self.model = model\n",
    "        self.prompt_template = \"\"\"\n",
    "        Create a comprehensive summary of the rhetorical analysis:\n",
    "        \n",
    "        Original Text: {text}\n",
    "        \n",
    "        Main Thesis: {thesis}\n",
    "        \n",
    "        Claims Analysis:\n",
    "        {claims_analysis}\n",
    "        \n",
    "        Generate a clear, concise summary that explains how rhetorical devices and logical fallacies are used in this text.\n",
    "        Focus on patterns and overall persuasive strategy.\n",
    "        \"\"\"\n",
    "    \n",
    "    def create_report(self, text: str, structure: TextStructure, \n",
    "                     claims_analysis: List[FallacyAnalysis]) -> AnalysisReport:\n",
    "        # Format claims analysis for prompt\n",
    "        claims_str = \"\\n\\n\".join(\n",
    "            f\"Claim: {analysis.claim}\\n\"\n",
    "            f\"Fallacies: {', '.join(f['name'] for f in analysis.detected_fallacies)}\\n\"\n",
    "            f\"Explanation: {analysis.explanation}\"\n",
    "            for analysis in claims_analysis\n",
    "        )\n",
    "        \n",
    "        # Generate summary using ChatNVIDIA interface\n",
    "        prompt = self.prompt_template.format(\n",
    "            text=text,\n",
    "            thesis=structure.thesis,\n",
    "            claims_analysis=claims_str\n",
    "        )\n",
    "        messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "        summary = self.model.invoke(messages).content\n",
    "        \n",
    "        return AnalysisReport(\n",
    "            text=text,\n",
    "            thesis=structure.thesis,\n",
    "            claims_analysis=claims_analysis,\n",
    "            summary=summary\n",
    "        )\n",
    "\n",
    "# Initialize Synthesizer agent\n",
    "synthesizer = SynthesizerAgent(ARCHITECT_MODEL)  # Using nano-9b-v2 for formatting\n",
    "print(\"Synthesizer Agent initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c2d12",
   "metadata": {},
   "source": [
    "## 7. Orchestration Logic\n",
    "\n",
    "Now we'll implement the main orchestration loop that coordinates our three agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3948222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veritas system initialized and ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "class VeritasOrchestrator:\n",
    "    def __init__(self):\n",
    "        self.architect = architect\n",
    "        self.rhetoric = rhetoric\n",
    "        self.synthesizer = synthesizer\n",
    "    \n",
    "    def analyze_text(self, text: str) -> AnalysisReport:\n",
    "        try:\n",
    "            # Step 1: Extract structure\n",
    "            logging.info(\"Analyzing text structure...\")\n",
    "            structure = self.architect.analyze_structure(text)\n",
    "            \n",
    "            # Step 2: Analyze each claim\n",
    "            logging.info(\"Analyzing claims for fallacies...\")\n",
    "            claims_analysis = []\n",
    "            for claim in structure.claims:\n",
    "                analysis = self.rhetoric.analyze_claim(claim)\n",
    "                claims_analysis.append(analysis)\n",
    "            \n",
    "            # Step 3: Generate final report\n",
    "            logging.info(\"Generating final report...\")\n",
    "            report = self.synthesizer.create_report(\n",
    "                text=text,\n",
    "                structure=structure,\n",
    "                claims_analysis=claims_analysis\n",
    "            )\n",
    "            \n",
    "            return report\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in analysis pipeline: {e}\")\n",
    "            raise\n",
    "\n",
    "# Initialize orchestrator\n",
    "veritas = VeritasOrchestrator()\n",
    "print(\"Veritas system initialized and ready for analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07fe1d3",
   "metadata": {},
   "source": [
    "# Testing Suite\n",
    "\n",
    "Let's test our system with a variety of challenging texts that exhibit different types of misinformation and rhetorical manipulation:\n",
    "\n",
    "1. **Emotional Appeal + Fear Mongering**\n",
    "2. **False Authority + Cherry Picking**\n",
    "3. **Conspiracy Theory Structure**\n",
    "4. **False Dichotomy + Slippery Slope**\n",
    "5. **Appeal to Nature + False Causation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ab4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 12:25:37,750 - INFO - Analyzing text structure...\n",
      "2025-10-13 12:25:41,993 - INFO - Analyzing claims for fallacies...\n",
      "2025-10-13 12:25:41,993 - INFO - Analyzing claims for fallacies...\n",
      "2025-10-13 12:26:03,146 - INFO - Generating final report...\n",
      "2025-10-13 12:26:03,146 - INFO - Generating final report...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Nemotron Veritas Analysis Report ===\n",
      "\n",
      "Main Thesis:\n",
      "Tech giants are destroying society by making teenagers anti-social through excessive social media use, and their influence is harmful to children's future.\n",
      "\n",
      "Claims Analysis:\n",
      "\n",
      "Claim: Teenagers spend excessive hours on social media, leading them to become 'anti-social zombies'.\n",
      "Detected Fallacies:\n",
      "Explanation: The claim does not misrepresent an opposing argument (Straw Man) nor does it attack a person's character instead of addressing their argument (Ad Hominem). While the term 'anti-social zombies' uses hyperbolic language, it serves as a conclusion about the perceived effects of social media rather than a direct fallacy against a specific argument or individual. No fallacies from the provided patterns are present in the claim.\n",
      "\n",
      "Claim: Experts who downplay the harms of screen time are biased, as they are allegedly paid by Big Tech.\n",
      "Detected Fallacies:\n",
      "- Ad Hominem\n",
      "Explanation: The claim attacks the character and potential bias of the experts by suggesting they are paid by Big Tech, rather than addressing the arguments or evidence they present regarding the harms of screen time. This is an ad hominem fallacy because it attempts to discredit the experts based on their alleged financial ties instead of engaging with their actual claims or research.\n",
      "\n",
      "Claim: Immediate banning of social media apps is necessary to prevent a generation of 'mindless drones' incapable of real conversation.\n",
      "Detected Fallacies:\n",
      "- Straw Man\n",
      "Explanation: The claim misrepresents the argument by suggesting that not banning social media apps would lead to a generation of 'mindless drones' incapable of real conversation. This exaggerates the potential consequences and sets up an extreme scenario that is easier to argue against, rather than addressing the nuanced discussion around social media's impact on communication skills.\n",
      "\n",
      "Summary:\n",
      "**Summary of Rhetorical Analysis:**  \n",
      "The text employs emotional appeals (pathos) through hyperbolic language like \"anti-social zombies\" and \"mindless drones\" to evoke fear and urgency about social media's societal harm. It uses **ad hominem** fallacies by attacking experts' credibility (claiming they are paid by Big Tech) rather than engaging with their arguments, and a **straw man** fallacy by exaggerating the consequences of inaction (e.g., \"generation of mindless drones\"). The persuasive strategy relies on demonizing tech giants as villains, undermining opposing viewpoints through bias accusations, and leveraging sensationalist rhetoric to advocate for extreme measures like app bans. These tactics aim to bypass critical scrutiny of evidence, prioritizing emotional manipulation over logical discourse to rally support for its thesis.\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: Emotional Appeal + Fear Mongering (Climate Change Denial)\n",
    "test_text_1 = \"\"\"\n",
    "Think about your children's future! The so-called 'green energy transition' is nothing but a scam that will destroy our economy \n",
    "and leave millions of hardworking Americans jobless. These climate alarmists want you to believe that every storm is a sign of \n",
    "impending doom, while they fly around in private jets. How many more families need to suffer under crushing energy prices before \n",
    "we wake up? If we don't stop this radical agenda now, our entire way of life will collapse, and China will dominate the world \n",
    "economy. The real science, which the mainstream media won't show you, proves that climate has always changed naturally.\n",
    "\"\"\"\n",
    "\n",
    "# Test Case 2: False Authority + Cherry Picking (Health Misinformation)\n",
    "test_text_2 = \"\"\"\n",
    "Dr. James Mitchell, a renowned wellness consultant with over 20 years of experience in alternative healing, has discovered what \n",
    "Big Pharma doesn't want you to know. In his groundbreaking research, which has been viewed by millions online, he found that \n",
    "common vaccines contain dangerous levels of toxins. A survey of his 500 patients showed that 78% reported feeling better after \n",
    "stopping vaccinations. Leading medical intuitive Sarah Bennett also confirms these findings. The pharmaceutical industry has \n",
    "spent billions trying to suppress this information, but the truth is finally coming out.\n",
    "\"\"\"\n",
    "\n",
    "# Test Case 3: Conspiracy Theory Structure (Political Manipulation)\n",
    "test_text_3 = \"\"\"\n",
    "Connect the dots, people! It's no coincidence that every major world event in the last decade has followed the exact same \n",
    "pattern. A small group of elite globalists, working through their puppet organizations, orchestrate these crises to consolidate \n",
    "power. Just look at who benefits financially - always the same players. They control the media, the banks, and even the \n",
    "weather through secret technology. Anyone who questions this narrative is immediately silenced or discredited. Wake up and see \n",
    "the bigger picture before it's too late!\n",
    "\"\"\"\n",
    "\n",
    "# Test Case 4: False Dichotomy + Slippery Slope (Education Policy)\n",
    "test_text_4 = \"\"\"\n",
    "There are only two choices in this critical debate about education: either we maintain strict traditional values in our schools, \n",
    "or we surrender our children to radical social experimenters. If we allow any changes to the current curriculum, it will start \n",
    "a devastating chain reaction. First, they'll remove classic literature, then they'll ban patriotic history, and before you know \n",
    "it, our children won't even learn basic math or science anymore. We must take a stand now - you're either with us or against \n",
    "our children's future.\n",
    "\"\"\"\n",
    "\n",
    "# Test Case 5: Appeal to Nature + False Causation (Health Products)\n",
    "test_text_5 = \"\"\"\n",
    "Nature provided us with everything we need for perfect health - no artificial chemicals required! Since the rise of synthetic \n",
    "medications in the 1950s, we've seen a dramatic increase in chronic diseases. This isn't a coincidence. Our ancestors lived \n",
    "disease-free lives using only natural remedies. Our premium organic wellness crystals, sourced from ancient healing sites, \n",
    "harness the earth's natural energy fields. Studies show that people who reject artificial medicines live happier lives. Isn't \n",
    "it time you returned to nature's way?\n",
    "\"\"\"\n",
    "\n",
    "# Function to analyze multiple texts\n",
    "def run_analysis_suite(texts):\n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f\"\\n{'='*20} Test Case {i} {'='*20}\\n\")\n",
    "        try:\n",
    "            report = veritas.analyze_text(text)\n",
    "            print(f\"Main Thesis:\\n{report.thesis}\\n\")\n",
    "            print(\"Claims Analysis:\")\n",
    "            for analysis in report.claims_analysis:\n",
    "                print(f\"\\nClaim: {analysis.claim}\")\n",
    "                print(\"Detected Fallacies:\")\n",
    "                for fallacy in analysis.detected_fallacies:\n",
    "                    print(f\"- {fallacy['name']}\")\n",
    "                print(f\"Explanation: {analysis.explanation}\")\n",
    "            print(f\"\\nSummary:\\n{report.summary}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing test case {i}: {str(e)}\")\n",
    "\n",
    "# Run all test cases\n",
    "test_texts = [test_text_1, test_text_2, test_text_3, test_text_4, test_text_5]\n",
    "run_analysis_suite(test_texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
